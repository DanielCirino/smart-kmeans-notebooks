{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ecde4b1352a3cf0d",
   "metadata": {},
   "source": [
    "This notebook performs data cleaning and preprocessing for each dataset listed in the configuration file. It removes unnecessary columns, handles missing values, and saves the clean DataFrame in an efficient format in the processed data folder."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b1a570c1c2764c1",
   "metadata": {},
   "source": [
    "### Configuration and Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d44d9badcaa1dee2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-31T23:21:02.887824Z",
     "start_time": "2025-08-31T23:21:02.853897Z"
    }
   },
   "outputs": [],
   "source": [
    "%run ../src/settings.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412864b8b67dfe5b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-31T23:21:05.523844Z",
     "start_time": "2025-08-31T23:21:05.223892Z"
    }
   },
   "outputs": [],
   "source": [
    "config = load_config()\n",
    "\n",
    "# Define processing parameters from config\n",
    "raw_data_path = config['data']['raw_path']\n",
    "processed_data_path = config['data']['processed_path']\n",
    "cols_to_drop = [\"RendaMedia\"]\n",
    "id_column = \"Cod_Setor\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44f6198ac404b0b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-31T23:21:37.537419Z",
     "start_time": "2025-08-31T23:21:37.527606Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "config = load_config()\n",
    "\n",
    "# Define os par√¢metros de processamento a partir do config\n",
    "raw_data_path = config['data']['raw_path']\n",
    "processed_data_path = config['data']['processed_path']\n",
    "cols_to_drop = [\"RendaMedia\"]\n",
    "id_column = \"Cod_Setor\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681e2c7fa30ae681",
   "metadata": {},
   "outputs": [],
   "source": [
    "processing_results = []\n",
    "\n",
    "for file_name in config['datasets']:\n",
    "  try:\n",
    "    # Load raw data\n",
    "    df_raw = load_raw_data(filename=file_name, data_path=raw_data_path)\n",
    "\n",
    "    # Prepare data (cleaning and feature selection)\n",
    "    df_processed = prepare_data(df_raw, cols_to_drop=cols_to_drop)\n",
    "\n",
    "    # Define output file name\n",
    "    output_file_name = f\"{file_name.split('.')[0]}.parquet\"\n",
    "\n",
    "    # Save result\n",
    "    res = save_processed_data(df_processed, filename=output_file_name,\n",
    "                              data_path=processed_data_path)\n",
    "\n",
    "    processing_results.append(\n",
    "      {'file_name': file_name,\n",
    "       'file_processed': res,\n",
    "       'total_rows': len(df_processed),\n",
    "       'status': 'success',\n",
    "       'error': None}\n",
    "    )\n",
    "\n",
    "  except Exception as e:\n",
    "    processing_results.append(\n",
    "      {'file_name': file_name,\n",
    "       'file_processed': None,\n",
    "       'total_rows': 0,\n",
    "       'status': 'error',\n",
    "       'error': str(e)}\n",
    "    )\n",
    "\n",
    "df_processing_results = pd.DataFrame(processing_results)\n",
    "display(df_processing_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
